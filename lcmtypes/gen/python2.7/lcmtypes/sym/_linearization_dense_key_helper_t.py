# This file automatically generated by skymarshal
# DO NOT MODIFY BY HAND
# fmt: off
# mypy: disallow-untyped-defs

import copy
import typing as T  # pylint: disable=unused-import

from io import BytesIO
import struct

class linearization_dense_key_helper_t(object):
    __slots__ = ["factor_offset", "combined_offset", "tangent_dim", "jacobian_storage_col_starts", "num_other_keys", "num_other_cols", "hessian_storage_col_starts"]  # type: T.List[str]

    def __init__(
        self,
        factor_offset=0,  # type: int
        combined_offset=0,  # type: int
        tangent_dim=0,  # type: int
        jacobian_storage_col_starts=None,  # type: T.Sequence[int]
        num_other_keys=0,  # type: int
        num_other_cols=0,  # type: int
        hessian_storage_col_starts=None,  # type: T.List[T.Sequence[int]]
        _skip_initialize=False,  # type: bool
    ):
        # type: (...) -> None
        """ If _skip_initialize is True, all other constructor arguments are ignored """
        if _skip_initialize:
            return
        # Offset of this key within the factor's state vector
        self.factor_offset = factor_offset
        # Offset of this key within the whole problem's state vector
        self.combined_offset = combined_offset
        # Tangent dimension of the key
        self.tangent_dim = tangent_dim
        self.jacobian_storage_col_starts = [] if jacobian_storage_col_starts is None else jacobian_storage_col_starts  # type: T.Sequence[int]
        # For each other key (from 0 to this key's index), the sparse storage valuePtr array offsets
        # NOTE(hayk): Currently num_other_cols is not constant in actual use - this type likely
        # can't be serialized right now. Perhaps try to store a flatter structure of slices.
        self.num_other_keys = num_other_keys
        self.num_other_cols = num_other_cols
        self.hessian_storage_col_starts = [] if hessian_storage_col_starts is None else hessian_storage_col_starts  # type: T.List[T.Sequence[int]]

    @staticmethod
    def _skytype_meta():
        # type: () -> T.Dict[str, str]
        return dict(
            type="struct",
            package="sym",
            name="linearization_dense_key_helper_t",
        )

    @classmethod
    def _default(cls):
        # type: () -> linearization_dense_key_helper_t
        return cls()

    def __repr__(self):
        # type: () -> str
        return "linearization_dense_key_helper_t({})".format(
            ", ".join("{}={}".format(name, repr(getattr(self, name))) for name in self.__slots__))

    def __eq__(self, other):
        # type: (object) -> bool
        if not isinstance(other, linearization_dense_key_helper_t):
            return NotImplemented
        return (
            (self.factor_offset==other.factor_offset) and
            (self.combined_offset==other.combined_offset) and
            (self.tangent_dim==other.tangent_dim) and
            (self.jacobian_storage_col_starts==other.jacobian_storage_col_starts) and
            (self.num_other_keys==other.num_other_keys) and
            (self.num_other_cols==other.num_other_cols) and
            (self.hessian_storage_col_starts==other.hessian_storage_col_starts)
        )
    # Disallow hashing for python struct lcmtypes.
    __hash__ = None  # type: ignore

    def encode(self):
        # type: () -> bytes
        buf = BytesIO()
        buf.write(linearization_dense_key_helper_t._get_packed_fingerprint())
        self._encode_one(buf)
        return buf.getvalue()

    def _encode_one(self, buf):
        # type: (T.BinaryIO) -> None
        buf.write(linearization_dense_key_helper_t._CACHED_STRUCT_0.pack(self.factor_offset, self.combined_offset, self.tangent_dim))
        v_num_jacobian_storage_col_starts = len(self.jacobian_storage_col_starts)
        buf.write(linearization_dense_key_helper_t._CACHED_STRUCT_1.pack(v_num_jacobian_storage_col_starts))
        buf.write(struct.pack('>%di' % v_num_jacobian_storage_col_starts, *self.jacobian_storage_col_starts[:v_num_jacobian_storage_col_starts]))
        buf.write(linearization_dense_key_helper_t._CACHED_STRUCT_2.pack(self.num_other_keys, self.num_other_cols))
        for i0 in range(self.num_other_keys):
            buf.write(struct.pack('>%di' % self.num_other_cols, *self.hessian_storage_col_starts[i0][:self.num_other_cols]))

    @staticmethod
    def decode(data):
        # type: (T.Union[bytes, T.BinaryIO]) -> linearization_dense_key_helper_t
        # NOTE(eric): This function can technically accept either a BinaryIO or
        # anything that supports the C++ Buffer Protocol,
        # which is unspecifiable in type hints.

        if hasattr(data, "read"):
            # NOTE(eric): mypy isn't able to figure out the hasattr check
            buf = T.cast(T.BinaryIO, data)
        else:
            buf = BytesIO(T.cast(bytes, data))

        if buf.read(8) != linearization_dense_key_helper_t._get_packed_fingerprint():
            raise ValueError("Decode error")
        return linearization_dense_key_helper_t._decode_one(buf)

    @staticmethod
    def _decode_one(buf):
        # type: (T.BinaryIO) -> linearization_dense_key_helper_t
        self = linearization_dense_key_helper_t(_skip_initialize=True)
        self.factor_offset, self.combined_offset, self.tangent_dim = linearization_dense_key_helper_t._CACHED_STRUCT_0.unpack(buf.read(12))
        v_num_jacobian_storage_col_starts = linearization_dense_key_helper_t._CACHED_STRUCT_1.unpack(buf.read(4))[0]
        self.jacobian_storage_col_starts = struct.unpack('>%di' % v_num_jacobian_storage_col_starts, buf.read(v_num_jacobian_storage_col_starts * 4))
        self.num_other_keys, self.num_other_cols = linearization_dense_key_helper_t._CACHED_STRUCT_2.unpack(buf.read(8))
        self.hessian_storage_col_starts = []
        for i0 in range(self.num_other_keys):
            self.hessian_storage_col_starts.append(struct.unpack('>%di' % self.num_other_cols, buf.read(self.num_other_cols * 4)))
        return self

    @staticmethod
    def _get_hash_recursive(parents):
        # type: (T.List[T.Type]) -> int
        if linearization_dense_key_helper_t in parents: return 0
        tmphash = (0x381e5cdfec61c814) & 0xffffffffffffffff
        tmphash = (((tmphash<<1)&0xffffffffffffffff)  + (tmphash>>63)) & 0xffffffffffffffff
        return tmphash

    _packed_fingerprint = None  # type: T.Optional[bytes]

    @staticmethod
    def _get_packed_fingerprint():
        # type: () -> bytes
        if linearization_dense_key_helper_t._packed_fingerprint is None:
            linearization_dense_key_helper_t._packed_fingerprint = struct.pack(">Q", linearization_dense_key_helper_t._get_hash_recursive([]))
        return linearization_dense_key_helper_t._packed_fingerprint

    def deepcopy(self, **kwargs):
        # type: (**T.Any) -> linearization_dense_key_helper_t
        """Ptree-style deep copy. Returns a copy w/ specified members replaced."""
        result = copy.deepcopy(self)
        for key in kwargs:
            if not hasattr(result, key):
                raise KeyError("Type linearization_dense_key_helper_t does not have attribute: " + str(key))
            setattr(result, key, kwargs[key])
        return result

    _CACHED_STRUCT_0 = struct.Struct(">iii")
    _CACHED_STRUCT_1 = struct.Struct(">i")
    _CACHED_STRUCT_2 = struct.Struct(">ii")
